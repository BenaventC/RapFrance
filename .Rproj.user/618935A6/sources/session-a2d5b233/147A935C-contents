---
title: "Rap francais"
format: 
  html:
    fig-width: 12
    fig-height: 9
execute:
  warning: false
  message: false
editor: visual
---

![rappeur](Bordeaux62-street-art-3GC-01.jpg)

# Stylométrie

## Lisibilité

Le rap c'est difficile à lire . Les scores de lisibilités sont incalculables, car la phrase est dissoutes, la ponctuation disparue. D'ailleurs la ponctuation est venue tardivement, le latin n'en avait pas. Qu'est-ce qui fait une phrase en l'absence de ponctuation ? La structure de la rime ? Le tempo de la phrase? Avons nous les outils ?

Le rap est un langage initiatique et ésotérique, un langage cryptique. plus difficile à lire que la philosophie. Les IA n'arrivent même pas bien à détecter leur langue.

Un biais apparaît par le fait que les transcriptions en vers, ignorent la ponctuation .... et produisent des phrases longues.

```{r 00}
library(tidyverse)
library(quanteda)
library(quanteda.textmodels)
library(quanteda.textstats)
library(ggwordcloud)
library(quanteda.textplots)
library(tidytext)
library(udpipe) 
library(Rtsne)
library(ggrepel)
library(seededlda)

# syntaxis and lexical annotations

My_Theme = theme(
  axis.title.x = element_text(size = 10),
  axis.text.x = element_text(size = 7),
  axis.text.y = element_text(size = 7),
  axis.title.y = element_text(size = 10))

theme_set(theme_minimal()+ theme_set(theme_minimal()))



text1<-read.csv("RapLyrics.csv")

```

# Avec des annotations

Ce sera plus concentré sur les mots qui retiennent le sens. Mais ça marche pas bien ! même pas du tout. Il n'y a pas de structure de phrase. On peut imaginer un transformer pour replacer les "." ?

```{r 12}
library(udpipe)
fr <- udpipe_download_model(language = "french")
udmodel_french <- udpipe_load_model(file = "french-gsd-ud-2.5-191206.udpipe")

#UD <- udpipe_annotate(udmodel_french, x=text1$Paroles, trace =200, parallel.cores = 4)

#UD <- as.data.frame(UD)

#saveRDS(UD, "UD.rds")

word<-UD %>% 
  group_by(lemma)%>%
  summarise(n=n())%>% arrange(n)%>%
  mutate(rank=rank(-n),
         sum=cumsum(n))


ggplot(word, aes(x=n, y=sum))+
  geom_point()+scale_y_log10()+
  scale_x_log10()+
  geom_smooth(method="gam")

write.csv(word,"word_token.csv")


```

```{r 13}
UD<- readRDS("UD.rds")

g<-UD%>%
  group_by(upos)%>%
  summarise(n=n())%>%
  ggplot(aes(x=reorder(upos,n), y=n))+
  geom_bar(stat = "identity")+
  coord_flip()
g

foo<-UD %>%
  group_by(token)%>%
  summarise(n=n())

foo

foo<-UD %>%
  filter(upos=="ADJ" |upos=="NOUN") %>%
  group_by(lemma, upos)%>%
  summarise(n=n()) %>%
  filter(n>80)%>%
  ggplot(aes(label = lemma, size = log(n), group=upos)) +
  geom_text_wordcloud(aes(color=upos)) +
  theme_minimal()+
  facet_wrap(vars(upos))

foo


foo1<-UD %>%
  mutate(id=paste0(doc_id,paragraph_id,sentence_id,token_id))%>%
  select(id, lemma)%>%
  rename(noun=lemma)

foo<-UD %>%
  filter(dep_rel=="amod")%>%
  mutate(id=paste0(doc_id,paragraph_id,sentence_id,head_token_id))%>%
  left_join(foo1)%>%
  select(id, lemma, noun)%>%
  rename(adj=lemma)%>%
  group_by(noun,adj)%>%
  summarise(n=n())%>%
  filter(n>5)
#A  Correspondance Analysis solution?
#igraph approach belong to the netx lesson 
library(igraph)
g <- graph.data.frame(foo, directed=FALSE)
V(g)$type <- bipartite_mapping(g)$type  ## Add the "type" attribute
V(g)$label.color <- ifelse(V(g)$type, "salmon4", "blue2")
V(g)$fill <- ifelse(V(g)$type, "salmon4", "blue2")
V(g)$shape <-ifelse(V(g)$type, "", "")
plot(g,vertex.label.cex = 0.8)
```

# Un Tsne with tf-idf

On calcule les tf idf et on projette les similarités dans un espace de faible dimension.

```{r 14}

UD<-readRDS("UD.rds")

index<-UD%>%
  group_by(doc_id)%>%
  summarise(n=n())%>%
  mutate(id=str_sub(4,))%>%
  arrange(id)

foo<-UD %>%
  filter(upos=="NOUN" |upos=="VERB" |upos=="ADJ" |upos=="ADV")%>%
  group_by(doc_id)%>%
  count(doc_id, lemma, sort=TRUE)%>%rename(word=lemma)

words <- foo %>% 
  group_by(word) %>% 
  summarize(total_word = n())

doc <- foo %>%
  group_by(doc_id) %>% 
  summarize(total_doc = n())

foo1<-foo %>%
  left_join(words)%>%
  filter(total_word>10)%>%
  pivot_wider(doc_id,names_from ="word", values_from = "n" )

foo1[is.na(foo1)]<-0

foo2<-foo1 %>%
  column_to_rownames(var="doc_id")

dfm<- as.dfm(foo2)

dfm_tf_idf<-dfm_tfidf(dfm)


df_tf_idf<-as.data.frame(dfm_tf_idf)


#just to keep words aside

foo2<-df_tf_idf%>%
  select(-doc_id)%>% 
  t()

word<-as.data.frame(rownames(foo2))%>%
  rename(word=1)

set.seed(42) # Sets seed for reproducibility
tsne_out <- Rtsne(foo2,
                  initial_dims = 20,
                  perplexity = 20,
                  partial_pca=TRUE,
                  theta=.5,
                  num_threads=4, 
                  verbose=1,
                  check_duplicates = FALSE)
tsne_out1<-tsne_out$Y
tsne_out2<-as.data.frame(cbind(word,tsne_out1)) %>%
  left_join(words)
  
ggplot(tsne_out2, aes(x=`1`, y=`2` ))+
  geom_text(aes(label=word, 
                      size=log(total_word),
                      alpha=10-log(total_word)))+
  theme(legend.position = "none")+
  labs(x=NULL, y=NULL)+  
  scale_size(range = c(.1, 3))

ggsave("tsne.svg",plot=last_plot(), width = 30, height = 20, units = "cm")

```

# Topic modelling

Une première version spontanée

```{r 15 }
library(seededlda)

set.seed(1234)
slda <- textmodel_lda(dfm_tf_idf, 20)

phi<-slda$phi %>% 
  as.data.frame() %>%
  rownames_to_column(var="topic") %>% 
  pivot_longer(-topic,names_to = "word", values_to = "p")%>%
  arrange(topic,p) %>%
  group_by(topic)%>%
  top_n(40)

ggplot(phi, aes(label=word))+
  geom_text_wordcloud(aes(size=p)) + 
  facet_wrap(vars(topic), ncol=4)+
  theme(strip.text.x = element_text(size = 6))+
    scale_size(range = c(1, 4))

phi$topic[phi$topic=="topic1"]<-"Traffic"
phi$topic[phi$topic=="topic2"]<-"Love"
phi$topic[phi$topic=="topic3"]<-"Ennui"
phi$topic[phi$topic=="topic4"]<-"Exister socialement"
phi$topic[phi$topic=="topic5"]<-"ouai ouai"
phi$topic[phi$topic=="topic6"]<-"Amour/haine"
phi$topic[phi$topic=="topic7"]<-"Le monde"
phi$topic[phi$topic=="topic8"]<-"Fou/fort"
phi$topic[phi$topic=="topic9"]<-"Mélancolie"
phi$topic[phi$topic=="topic10"]<-"Rapper"
phi$topic[phi$topic=="topic11"]<-"Le Temps qui passe"
phi$topic[phi$topic=="topic12"]<-"délinquance"
phi$topic[phi$topic=="topic13"]<-"Amis/ ennemis"
phi$topic[phi$topic=="topic14"]<-"Onomatopées"
phi$topic[phi$topic=="topic15"]<-"Responsabilité"
phi$topic[phi$topic=="topic16"]<-"respect/gang"
phi$topic[phi$topic=="topic17"]<-"Comprendre"
phi$topic[phi$topic=="topic18"]<-"American"
phi$topic[phi$topic=="topic19"]<-"Dignité"
phi$topic[phi$topic=="topic20"]<-"Violence"

ggplot(phi, aes(label=word))+
  geom_text_wordcloud(aes(size=p)) + 
  facet_wrap(vars(topic), ncol=4)+
  theme(strip.text.x = element_text(size =9))+
    scale_size(range = c(1, 4))


ggsave("topic_v01.svg",plot=last_plot(), width = 30, height = 20, units = "cm")


theta<-as.data.frame(slda$theta)


```

to do

-   test the semi-supervised seedlda model

-   and stm for time évolution.

```{r 16}


dfmat1 <-toks %>% 
  dfm()%>%
  dfm_trim(min_termfreq = 30, max_termfreq = 550)

set.seed(1234)


slda <- textmodel_lda(dfmat1, 20)

phi<-slda$phi %>% 
  as.data.frame() %>%
  rownames_to_column(var="topic") %>% 
  pivot_longer(-topic,names_to = "word", values_to = "p")%>%
  arrange(topic,p) %>%
  group_by(topic)%>%
  top_n(40)

ggplot(phi, aes(label=word))+
  geom_text_wordcloud(aes(size=p)) + 
  facet_wrap(vars(topic), ncol=4)+
  theme(strip.text.x = element_text(size = 6))+
    scale_size(range = c(1, 4))

ggsave("topic_V02.svg",plot=last_plot(), width = 30, height = 20, units = "cm")

phi$topic[phi$topic=="topic1"]<-"Traffic"
phi$topic[phi$topic=="topic2"]<-"Love"
phi$topic[phi$topic=="topic3"]<-"Ennui"
phi$topic[phi$topic=="topic4"]<-"Exister socialement"
phi$topic[phi$topic=="topic5"]<-"ouai ouai"
phi$topic[phi$topic=="topic6"]<-"Amour/haine"
phi$topic[phi$topic=="topic7"]<-"Le monde"
phi$topic[phi$topic=="topic8"]<-"Fou/fort"
phi$topic[phi$topic=="topic9"]<-"Mélancolie"
phi$topic[phi$topic=="topic10"]<-"Rapper"
phi$topic[phi$topic=="topic11"]<-"Le Temps qui passe"
phi$topic[phi$topic=="topic12"]<-"délinquance"
phi$topic[phi$topic=="topic13"]<-"Amis/ ennemis"
phi$topic[phi$topic=="topic14"]<-"Onomatopées"
phi$topic[phi$topic=="topic15"]<-"Responsabilité"
phi$topic[phi$topic=="topic16"]<-"respect/gang"
phi$topic[phi$topic=="topic17"]<-"Comprendre"
phi$topic[phi$topic=="topic18"]<-"American"
phi$topic[phi$topic=="topic19"]<-"Dignité"
phi$topic[phi$topic=="topic20"]<-"Violence"

ggplot(phi, aes(label=word))+
  geom_text_wordcloud(aes(size=p)) + 
  facet_wrap(vars(topic), ncol=4)+
  theme(strip.text.x = element_text(size =9))+
    scale_size(range = c(1, 4))




theta<-as.data.frame(slda$theta)

topic<-cbind(text1,theta) 

foo<-topic %>%
  group_by(quinc)%>%
  summarise(topic1=mean(topic1, na.rm=TRUE),
            topic10=mean(topic10,na.rm=TRUE),
            topic16=mean(topic16,na.rm=TRUE),
            topic19=mean(topic19,na.rm=TRUE))%>%
  pivot_longer(-quinc, names_to = "variable", values_to = "value" )

ggplot(foo, aes(x=quinc,y=value, group=variable ))+ 
  geom_line(stat="identity", aes(color=variable))

```
